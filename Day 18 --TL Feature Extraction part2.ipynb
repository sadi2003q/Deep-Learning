{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NlSeLZ72DdyP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "izyUC4R5EEmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad98e1e-16c7-46cb-aca6-dd6fb10952e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_UddQklDfbx",
        "outputId": "2a9bd5e2-abe5-4d88-c363-1dac6d193e39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
            "License(s): unknown\n",
            "Downloading cell-images-for-detecting-malaria.zip to /content\n",
            " 98% 665M/675M [00:06<00:00, 173MB/s]\n",
            "100% 675M/675M [00:06<00:00, 106MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/cell_image.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "K9qvcOvDEeXv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "ZKMjxBZM4NeA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top = False,\n",
        "    input_shape=(150, 150, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "5vI9EDukoUmn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "V2Q5gs28xiQs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "-01TC4GIxiOI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/cell_images',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size = 32,\n",
        "    image_size=(150, 150)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9PiImyyxiLy",
        "outputId": "66340582-97e4-4db0-94bf-8758bb49c834"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27558 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of batches for train and test\n",
        "total_batches = tensorflow.data.experimental.cardinality(data).numpy()\n",
        "train_size = int(0.8 * total_batches)"
      ],
      "metadata": {
        "id": "nbq0egBRxiGL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = data.take(train_size)\n",
        "test_ds = data.skip(train_size)"
      ],
      "metadata": {
        "id": "f8OUacAuxh-r"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(image, label):\n",
        "  image = tensorflow.cast(image/255., tensorflow.float32)\n",
        "  return (image, label)\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "test_ds =  test_ds.map(process)"
      ],
      "metadata": {
        "id": "M7h9NbyWxh8F"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NVGiMjQIxh4m"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN5UgsGixh0c",
        "outputId": "35eff6c8-cbf7-411d-babd-b1641065ce23"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 133ms/step - accuracy: 0.9456 - loss: 0.1516 - val_accuracy: 0.9461 - val_loss: 0.1557\n",
            "Epoch 2/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 112ms/step - accuracy: 0.9503 - loss: 0.1362 - val_accuracy: 0.9443 - val_loss: 0.1455\n",
            "Epoch 3/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 112ms/step - accuracy: 0.9510 - loss: 0.1332 - val_accuracy: 0.9414 - val_loss: 0.1521\n",
            "Epoch 4/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 112ms/step - accuracy: 0.9598 - loss: 0.1154 - val_accuracy: 0.9437 - val_loss: 0.1512\n",
            "Epoch 5/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 112ms/step - accuracy: 0.9582 - loss: 0.1168 - val_accuracy: 0.9456 - val_loss: 0.1456\n",
            "Epoch 6/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 112ms/step - accuracy: 0.9617 - loss: 0.1072 - val_accuracy: 0.9436 - val_loss: 0.1510\n",
            "Epoch 7/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 133ms/step - accuracy: 0.9660 - loss: 0.0938 - val_accuracy: 0.9481 - val_loss: 0.1466\n",
            "Epoch 8/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 133ms/step - accuracy: 0.9707 - loss: 0.0853 - val_accuracy: 0.9383 - val_loss: 0.1799\n",
            "Epoch 9/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 133ms/step - accuracy: 0.9721 - loss: 0.0801 - val_accuracy: 0.9316 - val_loss: 0.2218\n",
            "Epoch 10/10\n",
            "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 111ms/step - accuracy: 0.9681 - loss: 0.0832 - val_accuracy: 0.9432 - val_loss: 0.1632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VOedUkkH0dAT"
      },
      "execution_count": 31,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}