{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "id": "NlSeLZ72DdyP"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ],
   "metadata": {
    "id": "izyUC4R5EEmr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4ad98e1e-16c7-46cb-aca6-dd6fb10952e9"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cp: cannot stat 'kaggle.json': No such file or directory\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_UddQklDfbx",
    "outputId": "2a9bd5e2-abe5-4d88-c363-1dac6d193e39"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
      "License(s): unknown\n",
      "Downloading cell-images-for-detecting-malaria.zip to /content\n",
      " 98% 665M/675M [00:06<00:00, 173MB/s]\n",
      "100% 675M/675M [00:06<00:00, 106MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/cell_image.zip', 'r')\n",
    "zip_ref.extractall('/content')\n",
    "zip_ref.close()"
   ],
   "metadata": {
    "id": "K9qvcOvDEeXv"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "id": "ZKMjxBZM4NeA"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "    input_shape=(150, 150, 3)\n",
    ")"
   ],
   "metadata": {
    "id": "5vI9EDukoUmn"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  if layer.name == 'block5_conv1':\n",
    "    set_trainable=True\n",
    "  if set_trainable:\n",
    "    layer.trainable = False\n",
    "  else:\n",
    "    layer.trainable = False\n"
   ],
   "metadata": {
    "id": "uyaZ_xlw8I_8"
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "    model = Sequential()\n",
    "    model.add(conv_base)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "id": "V2Q5gs28xiQs"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "-01TC4GIxiOI"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = keras.utils.image_dataset_from_directory(\n",
    "    directory = '/content/cell_images',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size = 32,\n",
    "    image_size=(150, 150)\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9PiImyyxiLy",
    "outputId": "baed9602-c8a6-4ded-d25f-a712c4364fc0"
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 27558 files belonging to 2 classes.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the number of batches for train and test\n",
    "total_batches = tensorflow.data.experimental.cardinality(data).numpy()\n",
    "train_size = int(0.8 * total_batches)"
   ],
   "metadata": {
    "id": "nbq0egBRxiGL"
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_ds = data.take(train_size)\n",
    "test_ds = data.skip(train_size)"
   ],
   "metadata": {
    "id": "f8OUacAuxh-r"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def process(image, label):\n",
    "  image = tensorflow.cast(image/255., tensorflow.float32)\n",
    "  return (image, label)\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "test_ds =  test_ds.map(process)"
   ],
   "metadata": {
    "id": "M7h9NbyWxh8F"
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "NVGiMjQIxh4m"
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(train_ds, epochs=5, validation_data=test_ds)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HN5UgsGixh0c",
    "outputId": "120f3f4b-43b2-4ba5-dd9e-00bb55ef5364"
   },
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m80s\u001B[0m 113ms/step - accuracy: 0.8361 - loss: 0.4180 - val_accuracy: 0.9334 - val_loss: 0.1732\n",
      "Epoch 2/5\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m78s\u001B[0m 113ms/step - accuracy: 0.9288 - loss: 0.1843 - val_accuracy: 0.9187 - val_loss: 0.2122\n",
      "Epoch 3/5\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m81s\u001B[0m 112ms/step - accuracy: 0.9391 - loss: 0.1614 - val_accuracy: 0.9372 - val_loss: 0.1702\n",
      "Epoch 4/5\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 112ms/step - accuracy: 0.9441 - loss: 0.1488 - val_accuracy: 0.9439 - val_loss: 0.1491\n",
      "Epoch 5/5\n",
      "\u001B[1m689/689\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 112ms/step - accuracy: 0.9491 - loss: 0.1351 - val_accuracy: 0.9319 - val_loss: 0.1927\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "d"
   ],
   "metadata": {
    "id": "VOedUkkH0dAT"
   },
   "execution_count": 31,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
